{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кэширование в Python: алгоритм LRU\n",
    "\n",
    "Эта публикация – незначительно сокращенный перевод статьи Сантьяго Валдаррама [Caching in Python Using the LRU Cache Strategy](https://realpython.com/lru-cache-python/).\n",
    "\n",
    "---\n",
    "\n",
    "Кэширование – один из подходов, который при правильном использовании значительно ускоряет работу и снижает нагрузку на вычислительные ресурсы. В модуле стандартной библиотеки Python `functools` реализован декоратор `@lru_cache`, дающий возможность кэшировать вывод функций, используя стратегию [Least Recently Used](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B_%D0%BA%D1%8D%D1%88%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F) (LRU, «вытеснение давно неиспользуемых»). Это простой, но мощный метод, который позволяет использовать в коде возможности кэширования.\n",
    "\n",
    "В этом руководстве мы рассмотрим:\n",
    "- Какие стратегии кэширования доступны и как их реализовать с помощью декораторов\n",
    "- что такое LRU и как работает этот подход;\n",
    "- как повысить производительность программы с помощью декоратора `@lru_cache`;\n",
    "- как расширить функциональность декоратора `@lru_cache` и прекратить кэширование по истечении определенного интервала времени.\n",
    "\n",
    "\n",
    "# Кэширование и в чем его польза\n",
    "**Кэширование** – это метод оптимизации хранения данных, при котором операции с данными производятся эффективнее, чем в их источнике.\n",
    "\n",
    "Представим, что мы создаем приложение для чтения новостей, которое агрегирует новости из различных источников. Пользователь перемещается по списку, приложение загружает статьи и отображает их на экране.\n",
    "\n",
    "Как поступит программа, если читатель решит сравнить пару статей и станет многократно между ними перемещаться? Без кэширования приложению придется каждый раз получать одно и то же содержимое. В этом случае неэффективно используется и система пользователя, и сервер со статьями, на котором создается дополнительная нагрузка.\n",
    "\n",
    "Лучшим подходом после получения статьи было бы хранить контент локально. Когда пользователь в следующий раз откроет статью, приложение сможет открыть контент из сохраненной копии, вместо того, чтобы заново загружать материал из источника. В информатике этот метод называется *кэшированием*.\n",
    "\n",
    "# Реализация кэширования посредством словаря Python\n",
    "В Python можно реализовать кэширование, используя словарь. Вместо того, чтобы каждый раз обращаться к серверу, можно проверять, есть ли контент в кэше, и опрашивать сервер только если контента нет. В качестве ключа можно использовать URL статьи, а в качестве значения – ее содержимое:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Получаем статью...\n",
      "Забираем статью с сервера...\n",
      "Получаем статью...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"ru\" >\\n\\n  <head>\\n    <meta charset=\"utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width,minimum-scale=1,initial-scale=1\">\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\\n\\n        <meta name=\"theme-color\" content=\"#ffffff\">\\n\\n          <meta name=\"centrifugo-url\" content=\"wss://proglib.io/centrifugo/connection/websocket\">\\n      <meta name=\"centrifugo-user\" content=\"\">\\n      <meta name=\"centrifugo-token\" content=\"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIiLCJleHAiOjE2MDU1NzQ0OTh9.K2zcZi0FXwpj22EZeVXMiL3CADWYVsMk4-g2tu0E4P4\">\\n    \\n          \\t\\n\\t\\t\\t\\n\\n\\t<title>Всё, что нужно знать о декораторах Python\\n\\t</title>\\n\\t<meta name=\"description\" content=\"Содержательный туториал об устройстве, назначении и практическом использовании декораторов Python с многочисленными примерами программного кода.\"/> <meta\\n\\tname=\"keywords\" content=\"python,                 decorators,                 декоратор,                 декораторы,                 functools'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "cache = dict()\n",
    "\n",
    "def get_article_from_server(url):\n",
    "    print(\"Забираем статью с сервера...\")\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def get_article(url):\n",
    "    print(\"Получаем статью...\")\n",
    "    if url not in cache:\n",
    "        cache[url] = get_article_from_server(url)\n",
    "\n",
    "    return cache[url]\n",
    "\n",
    "get_article(\"https://proglib.io/p/vse-chto-nuzhno-znat-o-dekoratorah-python-2020-05-09\")[:1000]\n",
    "get_article(\"https://proglib.io/p/vse-chto-nuzhno-znat-o-dekoratorah-python-2020-05-09\")[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Для запуска этого примера у вас должна быть установлена библиотека `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#раскомментируйте следующую строку,\n",
    "# чтобы установить библиотеку из блокнота Jupyter\n",
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя вызов `get_article()` выполняется дважды, статья с сервера загружается лишь один раз. После первого доступа к статье мы помещаем ее URL и содержимое в словарь `cache`. Во второй раз код не требует повторного получения элемента с сервера.\n",
    "\n",
    "\n",
    "# Стратегии кэширования\n",
    "\n",
    "В этой простой реализации кэширования закралась очевидная проблема: содержимое словаря будет неограниченно расти: чем больше статей открыл пользователь, тем больше было использовано места в памяти.\n",
    "\n",
    "Чтобы обойти эту проблему, нам нужна стратегия, которая позволит программе решить, какие статьи пора удалить. Существует несколько различных стратегий, которые можно использовать для удаления элементов из кэша и предотвращения превышения его максимального размера. Пять самых популярных перечислены в таблице.\n",
    "\n",
    "Стратегия | Какую запись удаляем | Эти записи чаще других используют повторно\n",
    "--- | --- | ---\n",
    "First-In/First-Out (FIFO) | Самая старая | Новые\n",
    "Last-In/First-Out (LIFO) | Самая недавняя | Старые\n",
    "Least Recently Used (LRU) | Использовалась наиболее давно | Недавно прочитанные\n",
    "Most Recently Used (MRU) | Использовалась последней | Прочитанные первыми\n",
    "Least Frequently Used (LFU) | Использовалась наиболее редко | Использовались часто\n",
    "\n",
    "\n",
    "# Погружаемся в идею LRU-кэширования\n",
    "Кэш, реализованный посредством стратегии LRU, упорядочивает элементы в порядке их использования. Каждый раз, когда мы обращаемся к записи, алгоритм LRU перемещает ее в верхнюю часть кэша. Таким образом, алгоритм может быстро определить запись, которая дольше всех не использовалась, проверив конец списка.\n",
    "\n",
    "На следующем рисунке показано представление кэша после того, как пользователь запросил статью из сети.\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/lru_cache_1_1.2eb80a8b24a3.png\" width=\"500\"/>\n",
    "\n",
    "Статья сохраняется в последнем слоте кэша перед тем, как будет передана пользователю. На следующем рисунке показано, что происходит, когда пользователь запрашивает следующую статью.\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/lru_cache_2_1.8c4f225e79d0.png\" width=\"500\"/>\n",
    "\n",
    "Вторая статья занимает последний слот, перемещая первую статью вниз по списку.\n",
    "\n",
    "Стратегия LRU предполагает: чем позже использовался объект, тем больше вероятность, что он понадобится в будущем. Алгоритм сохраняет такой объект в кэше в течение максимально длительного времени.\n",
    "\n",
    "\n",
    "# Заглядываем за кулисы кэша LRU\n",
    "\n",
    "Один из способов реализовать кэш LRU в Python – использовать комбинацию [двусвязного списка](https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D1%8F%D0%B7%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D0%B8%D1%81%D0%BE%D0%BA) и [хеш-таблицы](https://ru.wikipedia.org/wiki/%D0%A5%D0%B5%D1%88-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0). Головной элемент двусвязного списка указывает на последнюю запрошенную запись, а хвостовой – на наиболее давно использовавшуюся.\n",
    "\n",
    "На рисунке ниже показана возможная структура реализации кэша LRU.\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/cache_internal_representation_1.6fdd3a39fa28.png\" width=\"400\"/>\n",
    "\n",
    "Используя хеш-таблицу, мы обеспечиваем доступ к каждому элементу в кэше, сопоставляя каждую запись с определенным местом в двусвязном списке. При этом доступ к недавно использовавшемуся элементу и обновление кэша – это операции, выполняемые за константное время (то есть с [временной сложностью](https://ru.wikipedia.org/wiki/%D0%92%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B0) алгоритма  $O(1)$).\n",
    "\n",
    "---\n",
    "\n",
    "**Примечание**. Примеры временной сложности различных функций Python рассматривались на proglib в статье [«Сложность алгоритмов и операций на примере Python»](https://proglib.io/p/slozhnost-algoritmov-i-operaciy-na-primere-python-2020-11-03).\n",
    "\n",
    "---\n",
    "\n",
    "Начиная с версии 3.2, для реализации стратегии LRU Python включает декоратор `@lru_cache`.\n",
    "\n",
    "\n",
    "# Использование `@lru_cache` для реализации кэша LRU в Python\n",
    "\n",
    "Декоратор `@lru_cache` за кулисами использует словарь. Результат выполнения функции кэшируется под ключом, соответствующим вызову функции и предоставленным аргументам. То есть чтобы декоратор работал, аргументы должны быть хешируемыми.\n",
    "\n",
    "\n",
    "## Наглядное представление алгоритма: перепрыгиваем ступеньки\n",
    "Представим, что мы хотим определить число способов, которыми можем достичь определенной ступеньки на лестнице. Сколько есть способов, например, добраться до четвертой ступеньки, если мы можем переступить-перепрыгнуть 1, 2, 3 (**но не более**) ступеньки? На рисунке ниже представлены соответствующие комбинации.\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/7_ways_to_make_it_to_4th_stair.2dea6527a4b7.png\" width=\"500\"/>\n",
    "\n",
    "Под каждым из рисунков приведен путь с указанием числа ступенек, преодоленных за один прыжок. При этом количество способов достижения четвертой ступеньки равно общему числу способов, которыми можно добраться до третьей, второй и первой ступенек:\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/combination-jumps-to-7th-stair-lru-cache_1.385e09435b81.png\" width=\"500\"/>\n",
    "\n",
    "Получается, что решение задачи можно разложить на более мелкие подзадачи. Чтобы определить различные пути к четвертой ступеньке, мы можем сложить четыре способа достижения третьей ступеньки, два способа достижения второй ступеньки и единственный способ для первой. То есть можно использовать рекурсивный подход.\n",
    "\n",
    "Опишем программно рекурсивное решение в точности, как мы его сейчас видим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "def steps_to(stair):\n",
    "    if stair == 1:\n",
    "        # До первой ступеньки можно добраться с пола \n",
    "        # единственным образом\n",
    "        return 1\n",
    "    elif stair == 2:\n",
    "        # Второй ступеньки можно достингуть,\n",
    "        # ступая по одной за раз или преодолев сразу две\n",
    "        return 2\n",
    "    elif stair == 3:\n",
    "        # Чтобы добраться до третьей ступеньки:\n",
    "        # 1. Перепрыгнуть сразу до третьей\n",
    "        # 2. Перепрыгнуть две, потом одну\n",
    "        # 3. Перепрыгнуть одну потом две\n",
    "        # 4. По одной за раз\n",
    "        return 4\n",
    "    else:\n",
    "        # Все промежуточные шаги это различные\n",
    "        # варианты прыжков через 1, 2 или 3 ступеньки,\n",
    "        # так что общее число вариантов - это сумма\n",
    "        # таких комбинаций\n",
    "        return (\n",
    "            steps_to(stair - 3)\n",
    "            + steps_to(stair - 2)\n",
    "            + steps_to(stair - 1)\n",
    "        )\n",
    "\n",
    "print(steps_to(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код работает для 4 ступенек. Давайте проверим, как он подсчитает число вариантов для лестницы из 30 ступенек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53798080"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_to(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось свыше 53 млн. комбинаций. Однако когда мы искали решение для тридцатой ступеньки, сценарий мог длиться довольно долго.\n",
    "\n",
    "# Засекаем время выполнения программного кода\n",
    "Измерим, как долго длится выполнение кода.\n",
    "\n",
    "---\n",
    "**Примечание**. О различных вариантах работы со временем в Python вы можете прочитать в публикации [«Назад в будущее: практическое руководство по путешествию во времени с Python»](https://proglib.io/p/nazad-v-budushchee-prakticheskoe-rukovodstvo-po-puteshestviyu-vo-vremeni-s-python-2019-12-01). Эта публикация также адаптирована в виде [блокнота Jupyter](https://github.com/matyushkin/lessons/blob/master/time/time_related.ipynb).\n",
    "\n",
    "---\n",
    "\n",
    "Для этого мы можем использовать модуль Python `timeit` или соответствующую команду в блокноте Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53 s ± 67.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "steps_to(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество секунд зависит от характеристик используемого компьютера. В моей системе расчет занял 3 секунды, что довольно медленно для всего тридцати ступенек. Это решение можно значительно улучшить c помощью [мемоизации](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D0%BC%D0%BE%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F).\n",
    "\n",
    "---\n",
    "**Примечание**. Один из примеров мемоизации рассматривался в статье [«Python и динамическое программирование на примере задачи о рюкзаке»](https://proglib.io/p/python-i-dinamicheskoe-programmirovanie-na-primere-zadachi-o-ryukzake-2020-02-04).\n",
    "\n",
    "---\n",
    "\n",
    "# Использование мемоизации для улучшения решения\n",
    "\n",
    "Наша рекурсивная реализация решает проблему, разбивая ее на более мелкие шаги, которые дополняют друг друга. На следующем рисунке показано дерево для семи ступенек, в котором каждый узел представляет определенный вызов `steps_to()`:\n",
    "\n",
    "<img src=\"https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/tree.3ebda400089a.png&w=1111&sig=849b7efff92dde86fb1d52e44f1f4e7aec27e3cc\" width=\"500\"/>\n",
    "\n",
    "Можно заметить, что алгоритму приходится вызывать `steps_to()` с одним и тем же аргументом несколько раз. Например, `steps_to(5)` вычисляется два раза, `steps_to(4)` – четыре раза, `steps_to(3)` – семь раз и т. д. Вызов одной и той же функции несколько раз запускает вычисления, в которых нет необходимости – результат всегда один и тот же.\n",
    "\n",
    "Чтобы решить эту проблему, мы можем использовать мемоизацию: мы сохраняем в памяти результат, полученный для одних и тех же входных значений и затем возвращаем при следующем аналогичном запросе. Прекрасная возможность применить декоратор `@lru_cache`!\n",
    "\n",
    "---\n",
    "**Примечание**. Если вы незнакомы с концепцией декораторов, но хотите глубже разобраться в вопросе, просто прочитайте материал[«Всё, что нужно знать о декораторах Python»](https://proglib.io/p/vse-chto-nuzhno-znat-o-dekoratorah-python-2020-05-09) (она также адаптирована в формате [Jupyter](https://github.com/matyushkin/lessons/blob/master/decorators/decorators.ipynb) и [Colab](https://colab.research.google.com/github/matyushkin/lessons/blob/master/decorators/decorators.ipynb)). Для наших задач достаточно знать, что это функции-обертки, которые позволяют модифицировать поведение функций и классов. Чтобы применить декоратор, достаточно объявить его перед определением функции.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Импортируем декоратор из модуля `functools` и применим к основной функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache()\n",
    "def steps_to(stair):\n",
    "    if stair == 1:\n",
    "        return 1\n",
    "    elif stair == 2:\n",
    "        return 2\n",
    "    elif stair == 3:\n",
    "        return 4\n",
    "    else:\n",
    "        return (steps_to(stair - 3)\n",
    "                + steps_to(stair - 2)\n",
    "                + steps_to(stair - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**.  В Python 3.8 и выше,  если вы не указываете никаких параметров, можно использовать декоратор `@lru_cache` без скобок. В более ранних версиях необходимо добавить круглые скобки: `@lru_cache()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.7 ns ± 3.4 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "steps_to(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От единиц секунд к десяткам наносекунд – потрясающее улучшение, обязанное тем, что за кулисами декоратор `@lru_cache` сохраняет результаты вызова `steps_to()` для каждого уникального входного значения.\n",
    "\n",
    "\n",
    "# Другие возможности @lru_cache\n",
    "\n",
    "Подключив декоратор `@lru_cache`, мы сохраняем каждый вызов и ответ в памяти для последующего доступа, если они потребуются снова. Но сколько таких комбинаций мы можем сохранить, пока не иссякнет память?\n",
    "\n",
    "У декоратора `@lru_cache` есть атрибут `maxsize`, определяющий максимальное количество записей до того, как кэш начнет удалять старые элементы. По умолчанию `maxsize` равен 128. Если мы присвоим `maxsize` значение `None`, то кэш будет расти без всякого удаления записей. Это может стать проблемой, если мы храним в памяти слишком много различных вызовов.\n",
    "\n",
    "Применим `@lru_cache` с использованием атрибута `maxsize` и добавим вызов метода `cache_info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CacheInfo(hits=52, misses=30, maxsize=16, currsize=16)\n"
     ]
    }
   ],
   "source": [
    "@lru_cache(maxsize=16)\n",
    "def steps_to(stair):\n",
    "    if stair == 1:\n",
    "        return 1\n",
    "    elif stair == 2:\n",
    "        return 2\n",
    "    elif stair == 3:\n",
    "        return 4\n",
    "    else:\n",
    "        return (steps_to(stair - 3)\n",
    "                + steps_to(stair - 2)\n",
    "                + steps_to(stair - 1))\n",
    "    \n",
    "steps_to(30)\n",
    "print(steps_to.cache_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем использовать информацию, возвращаемую `cache_info()`, чтобы понять, как работает кэш, и настроить его, чтобы найти подходящий баланс между скоростью работы и объемом памяти:\n",
    "\n",
    "- `hits=52` – количество вызовов, которые  `@lru_cache` вернул непосредственно из памяти, поскольку они присутствовали в кэше;\n",
    "- `misses=30` – количество вызовов, которые взяты не из памяти, а были вычислены (в случае нашей задачи это каждая новая ступень);\n",
    "- `maxsize=16` – это размер кэша, который мы определили, передав его  декоратору;\n",
    "- `currsize=16` – текущий размер кэша, в этом случае кэш заполнен.\n",
    "\n",
    "\n",
    "# Добавление срока действия кэша\n",
    "Перейдем от учебного примера к более реалистичному. Представьте, что мы хотим отслеживать появление на ресурсе Real Python новых статей, содержащих в заголовке слово `python` – выводить название, скачивать статью и отображать ее объем (число символов).\n",
    "\n",
    "Real Python предоставляет [протокол Atom](https://ru.wikipedia.org/wiki/Atom), так что мы можем использовать библиотеку `feedparser` для анализа канала и библиотеку `requests` для загрузки содержимого статьи, как мы это делали раньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расскоментируйте строку, чтобы установить библиотеку feedparser\n",
    "#!pip install feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "import ssl\n",
    "import time\n",
    "\n",
    "if hasattr(ssl, \"_create_unverified_context\"):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def get_article_from_server(url):\n",
    "    print(\"Получение статьи с сервера...\")\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def monitor(url):\n",
    "    maxlen = 45\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"\\nПроверям ленту...\")\n",
    "            feed = feedparser.parse(url)\n",
    "\n",
    "            for entry in feed.entries[:5]:\n",
    "                if \"python\" in entry.title.lower():\n",
    "                    truncated_title = (\n",
    "                        entry.title[:maxlen] + \"...\"\n",
    "                        if len(entry.title) > maxlen\n",
    "                        else entry.title\n",
    "                    )\n",
    "                    print(\n",
    "                        \"Совпадение:\",\n",
    "                        truncated_title,\n",
    "                        len(get_article_from_server(entry.link)),\n",
    "                    )\n",
    "\n",
    "            time.sleep(5)\n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрипт будет работать непрерывно, пока мы не остановим его, нажав `Ctrl + C` в окне терминала (или не прервем выполнение в Jupyter-блокноте)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Проверям ленту...\n",
      "Получение статьи с сервера...\n",
      "Совпадение: The Real Python Podcast – Episode #35: Securi... 28704\n",
      "Получение статьи с сервера...\n",
      "Совпадение: PyPy: Faster Python With Minimal Effort 67387\n",
      "Получение статьи с сервера...\n",
      "Совпадение: Handling Missing Keys With the Python default... 33224\n",
      "Получение статьи с сервера...\n",
      "Совпадение: Use Sentiment Analysis With Python to Classif... 158401\n",
      "Получение статьи с сервера...\n",
      "Совпадение: The Real Python Podcast – Episode #34: The Py... 29576\n",
      "\n",
      "Проверям ленту...\n",
      "Получение статьи с сервера...\n",
      "Совпадение: The Real Python Podcast – Episode #35: Securi... 28704\n",
      "Получение статьи с сервера...\n",
      "Совпадение: PyPy: Faster Python With Minimal Effort 67389\n",
      "Получение статьи с сервера...\n",
      "Совпадение: Handling Missing Keys With the Python default... 33224\n",
      "Получение статьи с сервера...\n",
      "Совпадение: Use Sentiment Analysis With Python to Classif... 158400\n",
      "Получение статьи с сервера...\n",
      "Совпадение: The Real Python Podcast – Episode #34: The Py... 29576\n"
     ]
    }
   ],
   "source": [
    "monitor(\"https://realpython.com/atom.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код загружает и анализирует xml-файл из RealPython. Далее цикл перебирает первые пять записей в списке. Если слово `python` является частью заголовка, код печатает заголовок и длину статьи. Затем код «засыпает» на 5 секунд, после чего вновь запускается мониторинг.\n",
    "\n",
    "Каждый раз, когда сценарий загружает статью, в консоль выводится сообщение «Получение статьи с сервера...». Если мы позволим скрипту работать достаточно долго, мы увидим, что это сообщение появляется повторно даже при загрузке той же ссылки.\n",
    "\n",
    "Мы можем использовать декоратор `@lru_cache`, однако содержание статьи со временем может измениться. При первой загрузке статьи декоратор сохранит ее содержимое и каждый раз будет возвращать одни и те же данные. Если сообщение обновлено, то сценарий мониторинга никогда об этом не узнает. Чтобы решить эту проблему, мы должны установить срок хранения записей в кэше.\n",
    "\n",
    "\n",
    "# Критерии исключения записей из кэша\n",
    "\n",
    "Мы можем реализовать описанную идею в новом декораторе, который расширяет `@lru_cache`. Кэш должен возвращать результат на запрос только, если срок кэширования записи еще не истек – в обратном случае результат должен забираться с сервера. Вот возможная реализация нового декоратора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache, wraps\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def timed_lru_cache(seconds: int, maxsize: int = 128):\n",
    "    def wrapper_cache(func):\n",
    "        func = lru_cache(maxsize=maxsize)(func)\n",
    "        \n",
    "        # инструментирование декоратора двумя атрибутами,\n",
    "        # представляющими время жизни кэша lifetime\n",
    "        # и дату истечения срока его действия expiration\n",
    "        func.lifetime = timedelta(seconds=seconds)\n",
    "        func.expiration = datetime.utcnow() + func.lifetime\n",
    "\n",
    "        @wraps(func)\n",
    "        def wrapped_func(*args, **kwargs):\n",
    "            if datetime.utcnow() >= func.expiration:\n",
    "                func.cache_clear()\n",
    "                func.expiration = datetime.utcnow() + func.lifetime\n",
    "\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        return wrapped_func\n",
    "\n",
    "    return wrapper_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Декоратор `@timed_lru_cache` реализует функциональность для оперирования временем жизни записей в кэше (в секундах) и максимальным размером кэша.\n",
    "\n",
    "Код оборачивает функцию декоратором `@lru_cache`. Это позволяет нам использовать уже знакомую функциональность кэширования. \n",
    "\n",
    "Перед доступом к записи в кэше декоратор проверяет, не наступила ли дата истечения срока действия. Если это так, декоратор очищает кэш и повторно вычисляет время жизни и срок действия. Время жизни распространяется на кэш в целом, а не на отдельные статьи.\n",
    "\n",
    "\n",
    "# Кэширование статей с помощью нового декоратора\n",
    "\n",
    "Теперь мы можем использовать новый декоратор `@timed_lru_cache` с функцией `monitor()`, чтобы предотвратить скачивание с сервера содержимого статьи при каждом новом запросе. Собрав код в одном месте, получим следующий результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Проверяем ленту...\n",
      "Получение статьи с сервера...\n",
      "Совпадение: The Real Python Podcast – Episode #35: Securi... 28704\n",
      "Получение статьи с сервера...\n",
      "Совпадение: PyPy: Faster Python With Minimal Effort 67387\n",
      "Получение статьи с сервера...\n",
      "Совпадение: Handling Missing Keys With the Python default... 33224\n",
      "Получение статьи с сервера...\n",
      "Совпадение: Use Sentiment Analysis With Python to Classif... 158400\n",
      "Получение статьи с сервера...\n",
      "Совпадение: The Real Python Podcast – Episode #34: The Py... 29576\n",
      "\n",
      "Проверяем ленту...\n",
      "Совпадение: The Real Python Podcast – Episode #35: Securi... 28704\n",
      "Совпадение: PyPy: Faster Python With Minimal Effort 67387\n",
      "Совпадение: Handling Missing Keys With the Python default... 33224\n",
      "Совпадение: Use Sentiment Analysis With Python to Classif... 158400\n",
      "Совпадение: The Real Python Podcast – Episode #34: The Py... 29576\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "import ssl\n",
    "import time\n",
    "\n",
    "from functools import lru_cache, wraps\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "if hasattr(ssl, \"_create_unverified_context\"):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def timed_lru_cache(seconds: int, maxsize: int = 128):\n",
    "    def wrapper_cache(func):\n",
    "        func = lru_cache(maxsize=maxsize)(func)\n",
    "        func.lifetime = timedelta(seconds=seconds)\n",
    "        func.expiration = datetime.utcnow() + func.lifetime\n",
    "\n",
    "        @wraps(func)\n",
    "        def wrapped_func(*args, **kwargs):\n",
    "            if datetime.utcnow() >= func.expiration:\n",
    "                func.cache_clear()\n",
    "                func.expiration = datetime.utcnow() + func.lifetime\n",
    "\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        return wrapped_func\n",
    "\n",
    "    return wrapper_cache\n",
    "\n",
    "@timed_lru_cache(60)\n",
    "def get_article_from_server(url):\n",
    "    print(\"Получение статьи с сервера...\")\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def monitor(url):\n",
    "    maxlen = 45\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"\\nПроверяем ленту...\")\n",
    "            feed = feedparser.parse(url)\n",
    "\n",
    "            for entry in feed.entries[:5]:\n",
    "                if \"python\" in entry.title.lower():\n",
    "                    truncated_title = (\n",
    "                        entry.title[:maxlen] + \"...\"\n",
    "                        if len(entry.title) > maxlen\n",
    "                        else entry.title\n",
    "                    )\n",
    "                    print(\n",
    "                        \"Совпадение:\",\n",
    "                        truncated_title,\n",
    "                        len(get_article_from_server(entry.link)),\n",
    "                    )\n",
    "\n",
    "            time.sleep(5)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        \n",
    "monitor(\"https://realpython.com/atom.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, как код печатает сообщение «Получение статьи с сервера ...» при первом доступе к соответствующим статьям. После этого, в зависимости от скорости cети, сценарий будет извлекать статьи из кэша несколько раз, прежде чем снова обратится к серверу.\n",
    "\n",
    "В приведенном примере скрипт пытается получить доступ к статьям каждые 5 секунд, а срок действия кэша истекает раз в минуту.\n",
    "\n",
    "\n",
    "# Заключение\n",
    "Кэширование – важный метод оптимизации, повышающий производительность любой программной системы. Понимание того, как работает кэширование, является фундаментальным шагом на пути к его эффективному включению в программный код.\n",
    "\n",
    "В этом уроке мы кратко рассмотрели:\n",
    "- какие бывают стратегии кэширования;\n",
    "- как работает LRU-кэширование в Python;\n",
    "- как использовать декоратор `@lru_cache`;\n",
    "- как рекурсивный подход в сочетании с кэшированием помогает достаточно быстро решить задачу.\n",
    "\n",
    "Следующим шагом к реализации различных стратегий кэширования в ваших приложениях может стать библиотека [cachetools](https://github.com/tkem/cachetools/), предоставляющая особые типы данных и декораторы, охватывающие самые популярные стратегии кэширования."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
